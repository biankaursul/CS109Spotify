{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spotlight.interactions import Interactions\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "data_path = '/Users/haoxinli/Downloads/mpd.v1/data/'\n",
    "playlist_folder = os.listdir(data_path)\n",
    "\n",
    "## Preparing data\n",
    "\n",
    "CF_baseline_Train = []\n",
    "CF_baseline_Val = []\n",
    "\n",
    "counter = 0\n",
    "for i in range(50):\n",
    "    with open(data_path+playlist_folder[i]) as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    playlists = raw_data['playlists']\n",
    "\n",
    "    for playlist in playlists:\n",
    "        pid = playlist['pid']\n",
    "        for track in playlist['tracks']:\n",
    "            track_uri = track['track_uri']\n",
    "            rand = random.random()\n",
    "            if rand < 0.8:\n",
    "                CF_baseline_Train.append([pid,track_uri])\n",
    "            else:\n",
    "                CF_baseline_Val.append([pid,track_uri])\n",
    "    counter += 1\n",
    "\n",
    "with open(\"CF_baseline_Train_40000.json\", \"w\") as f:\n",
    "    data_json = json.dump(CF_baseline_Train,f)\n",
    "    \n",
    "with open(\"CF_baseline_Val_10000.json\", \"w\") as f:\n",
    "    data_json = json.dump(CF_baseline_Val,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "\n",
    "with open('CF_baseline_Train_40000.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "users = [user for user, song in data]\n",
    "item = [song for user, song in data]\n",
    "\n",
    "## Assign id to each playlist title\n",
    "\n",
    "song_per_user = {}\n",
    "for user in users:\n",
    "    if user not in song_per_user.keys():\n",
    "        song_per_user[user] = 1\n",
    "    else:\n",
    "        song_per_user[user] += 1\n",
    "# print(len(song_per_user))\n",
    "\n",
    "\n",
    "pids = {}\n",
    "num = 0\n",
    "for user in song_per_user.keys():\n",
    "    pids[user] = num\n",
    "    num += 1\n",
    "# print(len(pids))\n",
    "    \n",
    "    \n",
    "users_transform = []\n",
    "for user in users:\n",
    "    users_transform.append(pids[user])\n",
    "# print(len(users_transform))\n",
    "    \n",
    "    \n",
    "## Assign id to each track id\n",
    "# appearance of each track\n",
    "count = {}\n",
    "for i in item:\n",
    "    if i not in count.keys():\n",
    "        count[i] = 1\n",
    "    else:\n",
    "        count[i] = count[i] + 1\n",
    "# print(len(count))\n",
    "        \n",
    "        \n",
    "item_id = {}\n",
    "id = 0\n",
    "for i in count.keys():\n",
    "    item_id[i] = id\n",
    "    id = id+1\n",
    "# print(len(item_id))\n",
    "\n",
    "\n",
    "item_transformed = []\n",
    "for i in item:\n",
    "    item_transformed.append(item_id[i])\n",
    "# print(len(item_transformed))\n",
    "    \n",
    "id_to_track = [0] * len(item_id.keys())\n",
    "for item in item_id.keys():\n",
    "    id_to_track[item_id[item]] = item\n",
    "# print(len(id_to_track))\n",
    "\n",
    "ratings = np.ones(len(item_transformed))\n",
    "\n",
    "data = Interactions(np.array(users_transform), np.array(item_transformed), ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: Collaborative Filtering\n",
    "#### Recommend songs based on other similar playlists, evaulated using R-Precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImplicitFactorizationModel(n_iter = 1)\n",
    "model.fit(data, verbose = 1)\n",
    "torch.save(model, 'baseline_model_40000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('baseline_model_40000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CF_baseline_Val_10000.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "validation = []\n",
    "\n",
    "playlist_num = data[0][0]\n",
    "songs = []\n",
    "for item in data:\n",
    "    playlist_num_new = item[0]\n",
    "    if playlist_num_new == playlist_num:\n",
    "        songs.append(item[1])\n",
    "        playlist_num = playlist_num_new\n",
    "    else:\n",
    "        validation.append(songs)\n",
    "        songs = []\n",
    "        songs.append(item[1])\n",
    "        playlist_num = playlist_num_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "users = np.array(range(40000))\n",
    "\n",
    "for playlist in validation[0:200]:\n",
    "\n",
    "    a = []\n",
    "    for item in playlist:\n",
    "        try:\n",
    "            a.append(item_id[item])\n",
    "        except:\n",
    "            pass\n",
    "    if len(a) > 3:\n",
    "        X_train, y_test = train_test_split(a, train_size = 0.7)\n",
    "    \n",
    "        dic = {}\n",
    "        score = np.array([0] * len(model.predict(1)))\n",
    "        sum_cos = 0\n",
    "\n",
    "        inp = np.array(X_train)\n",
    "        random.shuffle(users)\n",
    "        users = users[0:100]\n",
    "        for i in users:\n",
    "            s = model.predict(i, np.array(inp))\n",
    "            cos_sim = cosine_similarity(np.array([s]),np.array([inp]))\n",
    "            sum_cos = sum_cos + cos_sim\n",
    "            score = cos_sim * model.predict(i) + score\n",
    "        score = score / sum_cos\n",
    "\n",
    "        for index in np.argsort(score[0])[-1:-251:-1]:\n",
    "            dic[id_to_track[index]] = score[0][index]\n",
    "        ans = []\n",
    "\n",
    "        for item in dic:\n",
    "            ans.append(item_id[item])\n",
    "\n",
    "        count = 0\n",
    "        for song in y_test:\n",
    "            if song in ans:\n",
    "                count += 1 \n",
    "        scores.append(count/len(y_test))\n",
    "        print(np.array(scores).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007930596224636221"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_score = np.array(scores).mean()\n",
    "r_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
